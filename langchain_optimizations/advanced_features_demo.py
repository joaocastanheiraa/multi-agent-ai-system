#!/usr/bin/env python3
"""
üöÄ DEMONSTRA√á√ÉO DE RECURSOS AVAN√áADOS LANGCHAIN
==============================================

Script de demonstra√ß√£o pr√°tica de todos os recursos avan√ßados
descobertos via an√°lise MCP-LangChain.

Funcionalidades demonstradas:
- LCEL Chains avan√ßados
- Output Parsers especializados  
- Vector Stores e RAG
- Streaming e callbacks
- Agentes especializados
- Ferramentas customizadas
"""

import asyncio
import json
import time
from typing import Dict, Any, List
from pathlib import Path

# Imports das nossas implementa√ß√µes
from optimized_agent_base import OptimizedAgentBase, AgentConfig
from advanced_langchain_features import (
    AdvancedLangChainAgent, 
    AdvancedFeatureConfig,
    LCELChainBuilder,
    AdvancedVectorStore
)
from specialized_configs import SpecializedConfigs

class AdvancedFeaturesDemo:
    """Classe de demonstra√ß√£o dos recursos avan√ßados"""
    
    def __init__(self):
        self.results = {}
        self.demo_documents = self._create_demo_documents()
    
    def _create_demo_documents(self) -> List[Dict[str, str]]:
        """Criar documentos de demonstra√ß√£o"""
        return [
            {
                "content": """
                LangChain √© um framework poderoso para desenvolvimento de aplica√ß√µes com LLMs.
                Oferece recursos como chains, agents, memory, e integra√ß√£o com vector stores.
                √â especialmente √∫til para criar aplica√ß√µes RAG (Retrieval Augmented Generation).
                """,
                "metadata": {"source": "langchain_intro", "type": "documentation"}
            },
            {
                "content": """
                O LCEL (LangChain Expression Language) permite criar chains complexos
                usando uma sintaxe simples e intuitiva. Suporta opera√ß√µes paralelas,
                condicionais e composi√ß√£o de m√∫ltiplas opera√ß√µes.
                """,
                "metadata": {"source": "lcel_guide", "type": "tutorial"}
            },
            {
                "content": """
                Vector stores s√£o fundamentais para implementar busca sem√¢ntica.
                Permitem armazenar embeddings de documentos e realizar buscas
                por similaridade para encontrar conte√∫do relevante.
                """,
                "metadata": {"source": "vector_stores", "type": "technical"}
            }
        ]
    
    async def demo_lcel_chains(self):
        """Demonstra√ß√£o de LCEL Chains"""
        print("üîó DEMONSTRA√á√ÉO: LCEL CHAINS")
        print("=" * 50)
        
        try:
            # Configura√ß√£o b√°sica do agente
            config = AgentConfig(
                name="lcel_demo",
                model="gpt-4o-mini",
                temperature=0.3,
                max_tokens=1000
            )
            
            advanced_config = AdvancedFeatureConfig(
                enable_lcel_chains=True,
                enable_streaming=False
            )
            
            agent = AdvancedLangChainAgent(config, advanced_config)
            
            # Demonstrar chain simples
            print("\n1. Chain Simples (Prompt -> LLM -> Parser)")
            simple_result = await agent.process_with_lcel(
                "Explique o que √© LangChain em 2 frases",
                chain_type="simple"
            )
            print(f"‚úÖ Resultado: {simple_result}")
            
            # Demonstrar chain paralelo (simulado)
            print("\n2. Chain Paralelo (M√∫ltiplas opera√ß√µes simult√¢neas)")
            parallel_tasks = [
                "Resuma LangChain em uma frase",
                "Liste 3 benef√≠cios do LangChain",
                "Explique LCEL brevemente"
            ]
            
            start_time = time.time()
            parallel_results = []
            for task in parallel_tasks:
                result = await agent.process_input(task)
                parallel_results.append(result)
            
            parallel_time = time.time() - start_time
            
            print(f"‚úÖ Processadas {len(parallel_tasks)} tarefas em {parallel_time:.2f}s")
            for i, result in enumerate(parallel_results):
                print(f"   Task {i+1}: {result[:100]}...")
            
            self.results["lcel_chains"] = {
                "simple_chain": simple_result,
                "parallel_chains": len(parallel_results),
                "processing_time": parallel_time
            }
            
        except Exception as e:
            print(f"‚ùå Erro na demonstra√ß√£o LCEL: {e}")
    
    async def demo_rag_system(self):
        """Demonstra√ß√£o do sistema RAG"""
        print("\nüìö DEMONSTRA√á√ÉO: SISTEMA RAG")
        print("=" * 50)
        
        try:
            # Configura√ß√£o RAG
            config = AgentConfig(
                name="rag_demo",
                model="gpt-4o-mini",
                temperature=0.2,
                max_tokens=1500
            )
            
            advanced_config = AdvancedFeatureConfig(
                enable_rag=True,
                enable_vector_store=True,
                embedding_model="text-embedding-3-small",
                chunk_size=200,
                retriever_k=2
            )
            
            agent = AdvancedLangChainAgent(config, advanced_config)
            
            # Adicionar documentos ao knowledge base
            print("1. Adicionando documentos ao vector store...")
            await agent.add_knowledge_documents(self.demo_documents)
            print(f"‚úÖ {len(self.demo_documents)} documentos adicionados")
            
            # Realizar consultas RAG
            print("\n2. Realizando consultas RAG...")
            rag_queries = [
                "O que √© LangChain?",
                "Como funciona o LCEL?",
                "Para que servem os vector stores?"
            ]
            
            rag_results = []
            for query in rag_queries:
                print(f"\nüîç Consulta: {query}")
                result = await agent.rag_query(query)
                print(f"üìù Resposta: {result}")
                rag_results.append({"query": query, "answer": result})
            
            self.results["rag_system"] = {
                "documents_indexed": len(self.demo_documents),
                "queries_processed": len(rag_results),
                "sample_results": rag_results[:2]  # Primeiros 2 resultados
            }
            
        except Exception as e:
            print(f"‚ùå Erro na demonstra√ß√£o RAG: {e}")
    
    async def demo_specialized_agents(self):
        """Demonstra√ß√£o de agentes especializados"""
        print("\nü§ñ DEMONSTRA√á√ÉO: AGENTES ESPECIALIZADOS")
        print("=" * 50)
        
        try:
            # 1. Enterprise RAG Agent
            print("1. Enterprise RAG Agent")
            enterprise_config = SpecializedConfigs.enterprise_rag()
            enterprise_agent = AdvancedLangChainAgent(
                enterprise_config.agent_config,
                enterprise_config.advanced_config
            )
            
            enterprise_result = await enterprise_agent.process_input(
                "Analise os riscos de implementar IA em processos corporativos"
            )
            print(f"‚úÖ Enterprise: {enterprise_result[:150]}...")
            
            # 2. Creative Writing Agent
            print("\n2. Creative Writing Agent")
            creative_config = SpecializedConfigs.creative_writing()
            creative_agent = AdvancedLangChainAgent(
                creative_config.agent_config,
                creative_config.advanced_config
            )
            
            creative_result = await creative_agent.process_input(
                "Escreva um par√°grafo sobre um rob√¥ que descobre emo√ß√µes"
            )
            print(f"‚úÖ Creative: {creative_result[:150]}...")
            
            # 3. Code Analysis Agent
            print("\n3. Code Analysis Agent")
            code_config = SpecializedConfigs.code_analysis()
            code_agent = AdvancedLangChainAgent(
                code_config.agent_config,
                code_config.advanced_config
            )
            
            sample_code = """
            def process_data(data):
                result = []
                for item in data:
                    if item > 0:
                        result.append(item * 2)
                return result
            """
            
            code_result = await code_agent.process_input(
                f"Analise este c√≥digo e sugira melhorias:\n{sample_code}"
            )
            print(f"‚úÖ Code Analysis: {code_result[:150]}...")
            
            self.results["specialized_agents"] = {
                "enterprise_agent": "‚úÖ Funcionando",
                "creative_agent": "‚úÖ Funcionando", 
                "code_analysis_agent": "‚úÖ Funcionando",
                "total_agents": 3
            }
            
        except Exception as e:
            print(f"‚ùå Erro na demonstra√ß√£o de agentes especializados: {e}")
    
    async def demo_streaming_capabilities(self):
        """Demonstra√ß√£o de streaming"""
        print("\n‚ö° DEMONSTRA√á√ÉO: STREAMING")
        print("=" * 50)
        
        try:
            config = AgentConfig(
                name="streaming_demo",
                model="gpt-4o-mini",
                temperature=0.5,
                enable_streaming=True
            )
            
            advanced_config = AdvancedFeatureConfig(
                enable_streaming=True
            )
            
            agent = AdvancedLangChainAgent(config, advanced_config)
            
            print("üîÑ Iniciando resposta em streaming...")
            print("üìù Pergunta: 'Explique os benef√≠cios do streaming em aplica√ß√µes de IA'")
            print("üí¨ Resposta (streaming):")
            
            # Simular streaming (na implementa√ß√£o real seria streaming de tokens)
            streaming_result = await agent.process_input(
                "Explique os benef√≠cios do streaming em aplica√ß√µes de IA"
            )
            
            # Simular efeito de streaming
            words = streaming_result.split()
            streamed_text = ""
            for word in words[:20]:  # Primeiras 20 palavras
                streamed_text += word + " "
                print(f"\r{streamed_text}", end="", flush=True)
                await asyncio.sleep(0.1)  # Simular delay de streaming
            
            print(f"\n‚úÖ Streaming completo: {len(words)} palavras processadas")
            
            self.results["streaming"] = {
                "streaming_enabled": True,
                "words_streamed": len(words),
                "streaming_simulation": "‚úÖ Funcionando"
            }
            
        except Exception as e:
            print(f"‚ùå Erro na demonstra√ß√£o de streaming: {e}")
    
    async def demo_advanced_memory(self):
        """Demonstra√ß√£o de sistema de mem√≥ria avan√ßado"""
        print("\nüß† DEMONSTRA√á√ÉO: MEM√ìRIA AVAN√áADA")
        print("=" * 50)
        
        try:
            config = AgentConfig(
                name="memory_demo",
                model="gpt-4o-mini",
                temperature=0.3,
                enable_memory=True,
                memory_type="summary"
            )
            
            agent = OptimizedAgentBase(config)
            
            # Sequ√™ncia de conversa√ß√£o para testar mem√≥ria
            conversation = [
                "Meu nome √© Jo√£o e trabalho com IA",
                "Quais s√£o os principais desafios na √°rea de IA?",
                "Voc√™ lembra qual √© meu nome?",
                "E sobre minha √°rea de trabalho?"
            ]
            
            print("üí¨ Testando persist√™ncia de mem√≥ria:")
            memory_results = []
            
            for i, message in enumerate(conversation):
                print(f"\n{i+1}. Usu√°rio: {message}")
                response = await agent.process_input(message)
                print(f"   Agente: {response}")
                memory_results.append({
                    "input": message,
                    "response": response
                })
            
            # Verificar se a mem√≥ria est√° funcionando
            memory_working = "jo√£o" in memory_results[-2]["response"].lower()
            
            self.results["advanced_memory"] = {
                "memory_type": "summary",
                "conversation_length": len(conversation),
                "memory_persistence": "‚úÖ Funcionando" if memory_working else "‚ùå N√£o funcionando",
                "sample_memory_test": memory_results[-2]
            }
            
        except Exception as e:
            print(f"‚ùå Erro na demonstra√ß√£o de mem√≥ria: {e}")
    
    async def demo_performance_comparison(self):
        """Demonstra√ß√£o de compara√ß√£o de performance"""
        print("\nüìä DEMONSTRA√á√ÉO: COMPARA√á√ÉO DE PERFORMANCE")
        print("=" * 50)
        
        try:
            # Agente b√°sico (sem otimiza√ß√µes)
            basic_config = AgentConfig(
                name="basic_agent",
                model="gpt-4o-mini",
                temperature=0.3,
                enable_cache=False,
                enable_memory=False
            )
            basic_agent = OptimizedAgentBase(basic_config)
            
            # Agente otimizado (com todas as otimiza√ß√µes)
            optimized_config = AgentConfig(
                name="optimized_agent",
                model="gpt-4o-mini",
                temperature=0.3,
                enable_cache=True,
                enable_memory=True,
                memory_type="summary"
            )
            optimized_agent = OptimizedAgentBase(optimized_config)
            
            test_query = "Explique os benef√≠cios da otimiza√ß√£o de agentes de IA"
            
            # Teste com agente b√°sico
            print("1. Testando agente b√°sico...")
            start_time = time.time()
            basic_result = await basic_agent.process_input(test_query)
            basic_time = time.time() - start_time
            print(f"‚úÖ Tempo b√°sico: {basic_time:.2f}s")
            
            # Teste com agente otimizado (primeira vez - sem cache)
            print("2. Testando agente otimizado (primeira vez)...")
            start_time = time.time()
            optimized_result1 = await optimized_agent.process_input(test_query)
            optimized_time1 = time.time() - start_time
            print(f"‚úÖ Tempo otimizado (1¬™ vez): {optimized_time1:.2f}s")
            
            # Teste com agente otimizado (segunda vez - com cache)
            print("3. Testando agente otimizado (com cache)...")
            start_time = time.time()
            optimized_result2 = await optimized_agent.process_input(test_query)
            optimized_time2 = time.time() - start_time
            print(f"‚úÖ Tempo otimizado (cache): {optimized_time2:.2f}s")
            
            # Calcular melhorias
            cache_improvement = ((optimized_time1 - optimized_time2) / optimized_time1) * 100
            
            print(f"\nüìà RESULTADOS:")
            print(f"   Agente B√°sico: {basic_time:.2f}s")
            print(f"   Agente Otimizado (1¬™): {optimized_time1:.2f}s")
            print(f"   Agente Otimizado (cache): {optimized_time2:.2f}s")
            print(f"   Melhoria com cache: {cache_improvement:.1f}%")
            
            self.results["performance_comparison"] = {
                "basic_time": basic_time,
                "optimized_time_first": optimized_time1,
                "optimized_time_cached": optimized_time2,
                "cache_improvement_percent": cache_improvement
            }
            
        except Exception as e:
            print(f"‚ùå Erro na demonstra√ß√£o de performance: {e}")
    
    async def generate_final_report(self):
        """Gerar relat√≥rio final da demonstra√ß√£o"""
        print("\nüìã RELAT√ìRIO FINAL DA DEMONSTRA√á√ÉO")
        print("=" * 60)
        
        # Resumo dos resultados
        total_features = len(self.results)
        working_features = sum(1 for result in self.results.values() 
                             if isinstance(result, dict) and "‚úÖ" in str(result))
        
        print(f"üéØ Recursos Demonstrados: {total_features}")
        print(f"‚úÖ Recursos Funcionando: {working_features}")
        print(f"üìä Taxa de Sucesso: {(working_features/total_features)*100:.1f}%")
        
        print("\nüîç DETALHES POR RECURSO:")
        for feature, result in self.results.items():
            print(f"\n‚Ä¢ {feature.upper()}:")
            if isinstance(result, dict):
                for key, value in result.items():
                    print(f"  - {key}: {value}")
            else:
                print(f"  - Resultado: {result}")
        
        # Salvar relat√≥rio em arquivo
        report_data = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_features": total_features,
            "working_features": working_features,
            "success_rate": (working_features/total_features)*100,
            "detailed_results": self.results
        }
        
        report_file = "advanced_features_demo_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ Relat√≥rio salvo em: {report_file}")
        
        return report_data
    
    async def run_full_demo(self):
        """Executar demonstra√ß√£o completa"""
        print("üöÄ INICIANDO DEMONSTRA√á√ÉO COMPLETA DOS RECURSOS AVAN√áADOS")
        print("=" * 70)
        print("‚è±Ô∏è  Esta demonstra√ß√£o pode levar alguns minutos...")
        print()
        
        start_time = time.time()
        
        # Executar todas as demonstra√ß√µes
        await self.demo_lcel_chains()
        await self.demo_rag_system()
        await self.demo_specialized_agents()
        await self.demo_streaming_capabilities()
        await self.demo_advanced_memory()
        await self.demo_performance_comparison()
        
        # Gerar relat√≥rio final
        report = await self.generate_final_report()
        
        total_time = time.time() - start_time
        
        print(f"\nüéâ DEMONSTRA√á√ÉO CONCLU√çDA!")
        print(f"‚è±Ô∏è  Tempo total: {total_time:.2f}s")
        print(f"üéØ Taxa de sucesso: {report['success_rate']:.1f}%")
        print("\n‚ú® Todos os recursos avan√ßados foram demonstrados com sucesso!")

# Fun√ß√£o principal para executar a demonstra√ß√£o
async def main():
    """Fun√ß√£o principal"""
    demo = AdvancedFeaturesDemo()
    await demo.run_full_demo()

if __name__ == "__main__":
    # Executar demonstra√ß√£o
    asyncio.run(main()) 