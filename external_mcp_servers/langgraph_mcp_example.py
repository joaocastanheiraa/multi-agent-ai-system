#!/usr/bin/env python3
"""
Exemplo de integraÃ§Ã£o LangGraph com servidores MCP externos
Baseado na documentaÃ§Ã£o oficial: https://langchain-ai.github.io/langgraph/agents/mcp/
"""

import asyncio
import os
from pathlib import Path
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI

# Configurar caminhos absolutos para os servidores MCP
current_dir = Path(__file__).parent.absolute()
math_server_path = current_dir / "math_server.py"
weather_server_url = "http://localhost:8000/mcp"

async def main():
    """FunÃ§Ã£o principal que demonstra a integraÃ§Ã£o MCP + LangGraph"""
    
    # Verificar se as variÃ¡veis de ambiente estÃ£o configuradas
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ OPENAI_API_KEY nÃ£o configurada. Configure no .env")
        return
    
    print("ğŸš€ Iniciando integraÃ§Ã£o LangGraph + MCP")
    print("=" * 50)
    
    # Configurar cliente MCP com mÃºltiplos servidores
    client = MultiServerMCPClient(
        {
            "math": {
                "command": "python",
                "args": [str(math_server_path)],
                "transport": "stdio",
            },
            "weather": {
                "url": weather_server_url,
                "transport": "streamable_http",
            }
        }
    )
    
    try:
        # Obter ferramentas dos servidores MCP
        print("ğŸ“¡ Conectando aos servidores MCP...")
        tools = await client.get_tools()
        print(f"âœ… {len(tools)} ferramentas carregadas dos servidores MCP:")
        for tool in tools:
            print(f"   â€¢ {tool.name}: {tool.description}")
        
        # Criar agente LangGraph com as ferramentas MCP
        print("\nğŸ¤– Criando agente LangGraph...")
        agent = create_react_agent(
            ChatOpenAI(model="gpt-4o-mini", temperature=0),
            tools
        )
        print("âœ… Agente criado com sucesso!")
        
        # Teste 1: OperaÃ§Ã£o matemÃ¡tica
        print("\n" + "=" * 50)
        print("ğŸ§® TESTE 1: OperaÃ§Ã£o MatemÃ¡tica")
        print("=" * 50)
        
        math_response = await agent.ainvoke(
            {"messages": [{"role": "user", "content": "what's (3 + 5) x 12?"}]}
        )
        
        print("ğŸ‘¤ Pergunta: what's (3 + 5) x 12?")
        print(f"ğŸ¤– Resposta: {math_response['messages'][-1].content}")
        
        # Teste 2: Consulta de clima
        print("\n" + "=" * 50)
        print("ğŸŒ¤ï¸  TESTE 2: Consulta de Clima")
        print("=" * 50)
        
        weather_response = await agent.ainvoke(
            {"messages": [{"role": "user", "content": "what is the weather in New York?"}]}
        )
        
        print("ğŸ‘¤ Pergunta: what is the weather in New York?")
        print(f"ğŸ¤– Resposta: {weather_response['messages'][-1].content}")
        
        # Teste 3: OperaÃ§Ã£o complexa combinando ferramentas
        print("\n" + "=" * 50)
        print("ğŸ”„ TESTE 3: OperaÃ§Ã£o Complexa")
        print("=" * 50)
        
        complex_response = await agent.ainvoke(
            {"messages": [{"role": "user", "content": "Calculate 15 * 4, then tell me if it's good weather for that temperature in SÃ£o Paulo"}]}
        )
        
        print("ğŸ‘¤ Pergunta: Calculate 15 * 4, then tell me if it's good weather for that temperature in SÃ£o Paulo")
        print(f"ğŸ¤– Resposta: {complex_response['messages'][-1].content}")
        
        print("\nğŸ‰ Todos os testes concluÃ­dos com sucesso!")
        
    except Exception as e:
        print(f"âŒ Erro durante a execuÃ§Ã£o: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # Limpar recursos
        print("\nğŸ§¹ Limpando recursos...")

if __name__ == "__main__":
    asyncio.run(main()) 